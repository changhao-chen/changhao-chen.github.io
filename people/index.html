<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> people | Changhao Chen </title> <meta name="author" content="Changhao Chen"> <meta name="description" content="HKUST (GZ) PEAK-Lab is a research group dedicated to embodied AI and autonomous systems. Our mission is to bring AI into the physical open world by enabling machines to understand general motion, perceive 3D scenes, and actively navigate and interact with their surroundings."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, Changhao Chen, HKUST-GZ"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://changhao-chen.github.io/people/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Changhao</span> Chen </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/service/">service </a> </li> <li class="nav-item "> <a class="nav-link" href="/awards/">awards </a> </li> <li class="nav-item active"> <a class="nav-link" href="/people/">people <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">people</h1> <p class="post-description">HKUST (GZ) PEAK-Lab is a research group dedicated to embodied AI and autonomous systems. Our mission is to bring AI into the physical open world by enabling machines to understand general motion, perceive 3D scenes, and actively navigate and interact with their surroundings.</p> </header> <article> <div class="post"> <article> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/chenchanghao-480.webp 480w,/assets/img/chenchanghao-800.webp 800w,/assets/img/chenchanghao-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/chenchanghao.png" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="chenchanghao.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>Changhao Chen is an assistant professor at the Intelligent Transportation Thrust and Artificial Intelligence Thrust, HKUST (GZ). He received Ph.D. in Computer Science from University of Oxford. His research interests lie in embodied AI and autonomous systems, particularly the challenges of open-world perception and navigation.</p> </div> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/zhouchangqing-480.webp 480w,/assets/img/zhouchangqing-800.webp 800w,/assets/img/zhouchangqing-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/zhouchangqing.png" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="zhouchangqing.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>Changqing Zhou is a Ph.D. student at HKUST-GZ, where he is advised by Prof. Changhao CHEN. He holds an M.S. in Artificial Intelligence from NTU and a B.S. in Mechanical Engineering from SJTU. His research interests focus on 3D vision and scene understanding. He aims to develop embodied agents capable of perceiving and interacting with the real world, with the ultimate goal of delivering tangible benefits to everyday life.</p> </div> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/jiangzeyu-480.webp 480w,/assets/img/jiangzeyu-800.webp 800w,/assets/img/jiangzeyu-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/jiangzeyu.png" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="jiangzeyu.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>Zeyu Jiang is a PhD student at HKUST-GZ, supervised by Prof. Changhao Chen. Previously, he obtained his master’s degree at NTU and bachelor’s degree at BIT. His research interests focus on embodied perception based on visual SLAM. He is interested in robotics and committed to joining the development of embodied AI into the physical world.</p> </div> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/shendehan-480.webp 480w,/assets/img/shendehan-800.webp 800w,/assets/img/shendehan-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/shendehan.png" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="shendehan.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>Dehan Shen is a research assistant working with Prof. Changhao Chen. He graduated from the University of Sheffield with a Master’s degree in Robotics and from Shanghai University with a Bachelor’s degree in Electronic Information Engineering. His research interests include learning-based inertial odometry and proprioceptive intelligence.</p> </div> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/zhangyufei-480.webp 480w,/assets/img/zhangyufei-800.webp 800w,/assets/img/zhangyufei-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/zhangyufei.jpg" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="zhangyufei.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>Yufei Zhang is a research assistant in PEAK lab working with Prof. Chen Changhao. He received his undergraduate degree from the School of Information Science and Engineering of Fudan University and his postgraduate degree from Nanyang Technological University. His current research interests include multimodal continuous learning and embodied intelligence.</p> </div> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/chengrenmin-480.webp 480w,/assets/img/chengrenmin-800.webp 800w,/assets/img/chengrenmin-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/chengrenmin.png" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="chengrenmin.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>Renmin Cheng is a research assistant at HKUST(GZ) working with Prof.Changhao Chen. Before that, He works as RD at Baidu. He graduated from Xidian Uninersity with a Master’s degree in Engineering , and from the Heilongjiang University with an undergraduate degree in Engineering.</p> </div> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/liujialong-480.webp 480w,/assets/img/liujialong-800.webp 800w,/assets/img/liujialong-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/liujialong.png" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="liujialong.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>Jialong Liu Research Assistant Working with Prof. Changhao Chen at HKUST (GZ). Graduated from Guangdong University of Technology. Has participated in multiple robotic competitive events. Interested in integrating algorithms and hardware for robot control.</p> </div> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/zhanghan-480.webp 480w,/assets/img/zhanghan-800.webp 800w,/assets/img/zhanghan-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/zhanghan.jpg" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="zhanghan.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>Han Zhang is an MPhil student at HKUST(GZ), working in the PEAK Lab under the supervision of Prof. Changhao Chen. He received his bachelor’s degree in Data Science from Jilin University. His research interests lie in 3D vision and Vision-Language-Action (VLA) models, with a focus on enhancing robotic perception and world understanding.</p> </div> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/tukunpeng-480.webp 480w,/assets/img/tukunpeng-800.webp 800w,/assets/img/tukunpeng-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/tukunpeng.png" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="tukunpeng.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>Kunpeng Tu is an MPhil student at the PEAK Lab, HKUST (Guangzhou). He received his B.Eng. degree in Aircraft Engineering from Moscow Aviation Institute. His research focuses on SLAM for robotics and UAVs. His research interests include visual–inertial odometry, mapping in complex environments, and perception-driven aerial intelligence.</p> </div> </article> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Changhao Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>